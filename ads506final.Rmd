---
title: "ads506final"
author: "Angela Zhang, Martin Zagari, & Omar Elfeky"
date: "11/23/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#Import necessary package
library(xts) 
library(tsbox)
library(astsa) 
library(tseries)
library(magrittr)
library(ggplot2)
#library(urca)
#library(fpp2)
library(tidyverse)
library(forecast)
library(x12)
```

```{r}
#Import the dataset
#We should use a common path.
#df<-read.csv("C:/Users/Angela Zhang/Desktop/daily_csv.csv")
df_daily<-read.csv("C:/ADS-506-Group-2/natgas/daily_csv.csv")
df_monthly<-read.csv("C:/ADS-506-Group-2/natgas/monthly_csv.csv")

#Inspect Data

head(df_monthly)

#Monthly data is more useable, for now we will use it. We should use daily data if we will use smoothing.
tail(df_monthly)

#Statistical Measures of dataset
summary(df_monthly)

#Looks like there is one null value for price

#Remove null values
df_daily <- na.omit(df_daily)
df_monthly <- na.omit(df_monthly)
#Row with null value has been successfully removed

#Converting the dataframes into time series.
#format =  "%Y-%m-%d"
#daily2 <- xts(df_daily[,-1], order.by=as.Date(df_daily[,1], format))
daily <- ts(df_daily)
#str(daily)
monthly <- ts(df_monthly[,c(2)], start=c(1997, 1), end=c(2020, 8), frequency=12)


#par(mfrow = c(2,1))
#Graph of the monthly data
tsplot(monthly, ylim=c(0,20), main="MonthlyNatGas Prices")
#daily
#Graph of the daily data
#plot(daily, ylim=c(0,20), lwd=2, col=4)
```


### Not sinuisoidal! Data from January 1997 and August 2020, prices from
```{r}
#Note: changing from monthly to daily made the plotted red since wave a straight line :/

trnd <- time(monthly)
C <- cos(2*pi*trnd/4)
S <- sin(2*pi*trnd/4)
fit <- lm(monthly~ trnd + C + S, na.action = NULL)
summary(monthly)
tsplot(monthly, col = gray(.5))
lines(fitted(fit), col = "red", lwd = 2)
lines(lowess(trnd, monthly, f = .05), lwd = 2, col = "#1B842C")
```


```{r}

#TODO 1 Make moving average of the daily data so its weekly.
#avgD = filter(daily,sides = 2, filter = rep(1/7, 7))

#TODO 2 Get residuals and comment if it is white noise.
#tsplot(diff(log(daily)), ylab="Daily NatGas Price Residuals", col=4)
#abline(h = mean(diff(log(daily))), col=6)

#TODO 3 Add something about ACF/Lag?

#TODO 4 Add linear regression and trend line?
#fit_monthly = lm(monthly$Price~0 + monthly$Date) #regression
#min_yb = floor(min(monthly$Price)); 
#max_yb = ceiling(max(monthly$Price)) #sets y-axis limit
#plot(monthly$Date, y, ylim=c(min_yb,max_yb), type="l", main=paste("Linear Trend Plus Noise Series: ",i)) #plots
#lines(monthly$Date, fitted(fit_b), col="blue") #fitted line (blue, solid)
#lines(monthly$Date, mu_b, col="red",lty=2) #true mean (red, dashed)

#TODO 5 Fit ARIMA model and Forecast 12 months (what kind of ARIMA model? what values of p,q,d?)


#TODO 6 Add titles/labels for all graphs.

```

```{r}

monthly.diff = diff(monthly)
monthly2.diff = diff(monthly)
monthly.log = log(monthly)
monthly.sqrt = sqrt(monthly)
monthly.diff.diff = diff(diff(monthly))
monthly.diff.log = diff(log(monthly))
monthly.diff.sqrt = diff(sqrt(monthly))
lambda = BoxCox.lambda(monthly, method = 'loglik')
 lambda
monthly.lambda = (monthly^lambda)

adf.test(monthly)
adf.test(monthly.diff)#P-value of 0.01
adf.test(monthly.diff.diff)#P-value of 0.01
adf.test(monthly.log)
adf.test(monthly.sqrt)
adf.test(monthly.diff.sqrt)#P-value of 0.01
#Still high p-value.
adf.test(monthly.lambda)



#Examine the plots of transformed (differenced) data
tsplot(monthly.diff, main = "Differenced Gas Price (monthly)")
#tsplot(monthly, main = "Gas Price (monthly)")
#tsplot(monthly.sqrt, main = "Sqrt Gas Price (monthly)")
#tsplot(monthly.log, main = "Log Gas Price (monthly)")
#tsplot(monthly.diff.log, main = "Differenced Differenced Gas Price (monthly)")
#tsplot(monthly.diff.log, main = "Differenced Logged Gas Price (monthly)")
#tsplot( monthly.diff.sqrt, main = "Differenced Sqrt Gas Price (monthly)")
```
```{r}
# Automated forecasting using an ARIMA model
fit <- auto.arima(monthly)
# predictive accuracy
accuracy(fit)
# predict next 5 observations DOES NOT WORK 
#forecast(fit, 5)
#plot(forecast(fit, 5))
fit2 <- arima(monthly.diff, order=c(2, 0, 2))
accuracy(fit2)
```


NEW
SEGMENTING THE MONTHLY TIME SERIES BY PERIOD
```{r}
par(mfrow = c(3,1))
mo_thru_2000 <- window(monthly, end = c(2000,6))
tsplot(mo_thru_2000)
mo_2001_2010 <- window(monthly, start = c(2000,7), end = c(2010,12))
tsplot(mo_2001_2010)
mo_after_2010 <- window(monthly, start = c(2011,1))
tsplot(mo_after_2010)

acf2(mo_thru_2000)
acf2(diff(mo_thru_2000))

acf2(mo_2001_2010)
acf2(diff(mo_2001_2010))

acf2(mo_after_2010)
acf2(diff(mo_after_2010))

#Based on the literature suggesting an ARIMA(2,1,2) as a benchmark, we started there.  It seems the best fit is MA2 with one difference.
sarima(monthly, p=2, d=1, q=2, no.constant=TRUE)
sarima(monthly, p=1, d=1, q=2, no.constant=TRUE)
sarima(monthly, p=0, d=1, q=2, no.constant=TRUE)
sarima(monthly, p=0, d=1, q=3, no.constant=TRUE)
sarima(monthly, p=2, d=0, q=2, no.constant=TRUE)
#u <- length(monthly) - 132
#monthly2 <- ts(monthly[u:length(monthly)], start = c(1947 + floor(u/4), u %% 4), frequency=4)
```


```{r}
#Seasonality plots again don't work with daily data, only monthly
# Plot of components
plot(decompose(monthly)) 

#Try multiplicative decompositon since errors are not "white noisy".  The error is much smaller with the multiplicative model (see scale) and the seasonal compoenent is somewhat larger
plot(decompose(monthly, type = "multiplicative"))


# Directly plotting a forecast of a model
plot(forecast(auto.arima(monthly),12))

# Time series specific plots
#All years have the same trend where the winter months are high and the summer is low. There are two years that are outliers. Maybe we should remove those years?
ggseasonplot(monthly) + theme_minimal()

#This shows that the trends and means of the months are about the same per year
ggmonthplot(monthly)

library(fpp2)
monthly.decomp <- stl(monthly, t.window=15, s.window="periodic", robust=TRUE)
plot(monthly.decomp, main = "STL Decomposition of NatGas Prices")

#S&P 500 open values from yahoo finance
df_sp500<-read.csv("C:/ADS-506-Group-2/natgas/sp500monthly.csv")
sp500 <- ts(df_sp500[,c(2)], end=c(2020, 8),start=c(1997, 1), frequency=12)
sp500 <- na.omit(sp500)
df_comp.joint = ts.intersect(monthly,sp500)
colnames(df_comp.joint) =  c("NatGas Price","S&P 500 Price Index")
plot(df_comp.joint , yax.flip=T, main = "Timeseries plot of NatGas Price and S&P 500 Price Index")
```




NEW
SEGMENTING THE DAILY(XTS) TIME SERIES BY PERIOD
XTS is a better object for daily TS as well as comparing multiple TS
###### ```{r, eval = FALSE} prevents the code block from running.
```{r, eval = FALSE}
par(mfrow = c(3,1))
dly_thru_2000 <- daily["/2000-06-30"]
plot(dly_thru_2000)
dly_2001_2010 <- daily["2000-07-01/2010-12-30"]
plot(dly_2001_2010)
dly_after_2010 <- daily["2011-01-01/"]
plot(dly_after_2010)

acf2(dly_thru_2000)
acf2(diff(dly_thru_2000))
acf2(  (diff(dly_thru_2000))^2  )

acf2(dly_2001_2010)
acf2(diff(dly_2001_2010))

acf2(dly_after_2010)
acf2(diff(dly_after_2010))
#u <- length(monthly) - 132
#monthly2 <- ts(monthly[u:length(monthly)], start = c(1947 + floor(u/4), u %% 4), frequency=4)

#Based on the literature suggesting an ARIMA(2,1,2) as a benchmark, we started there.  It seems the best fit is MA2 with one difference.
sarima(daily, p=2, d=1, q=2, no.constant=TRUE)
sarima(daily, p=1, d=1, q=2, no.constant=TRUE)
sarima(daily, p=0, d=1, q=2, no.constant=TRUE)
sarima(daily, p=0, d=1, q=3, no.constant=TRUE)
```
QUESTION 5.3:  *********************************
Crude oil prices in dollars per barrel are in oil. Fit an ARIMA(p,d,q) model to the growth rate performing all necessary diagnostics. Comment.

STEPS 1 and 2: Plotting and transforming.

Due to periodic large excursions in growth rates as well as substanial non-linear trend, the data appear to benefit from both log transformation and differencing, as shown below.  In particular, differencing alone appears to leave a non-constant variance in the differences, which is ameliorated with transforming with log first and then differencing.

Unfortunately, even with transformation and double-differening the errors appear autocorrelated, so we may have to look at a linear model followed by ARMA for the residuals.


##### We need to change the below to use monthly data.
```{r, eval = FALSE}

library(astsa)

BrentPrice <-read.csv("C:/ADS-506-Group-2/natgas/BrentPrice.csv")
BrentPrice <- na.omit(BrentPrice)
BrentPrice %>% drop_na()
oilformat =  "%d-%h-%y"
BrentPrice$Date <- as.Date(BrentPrice$Date, oilformat)

dailyBr <- xts(BrentPrice$Price, BrentPrice$Date)
dailyBr1 <- dailyBr["/2000-6-30"]
dailyBr2 <- dailyBr["2000-07-01/2010-12-30"]
dailyBr3 <- dailyBr["/2011-01-01"]

dailyBoth <- merge(daily, dailyBr, join = "inner")
plot(dailyBoth)
head(dailyBoth)

library(lmtest)
grangertest(daily ~ dailyBr, order = 1, data = dailyBoth)
grangertest(daily ~ dailyBr, order = 2, data = dailyBoth)
grangertest(daily ~ dailyBr, order = 3, data = dailyBoth)
grangertest(daily ~ dailyBr, order = 5, data = dailyBoth)
grangertest(daily ~ dailyBr, order = 10, data = dailyBoth)
grangertest(daily ~ dailyBr, order = 20, data = dailyBoth)
grangertest(daily ~ dailyBr, order = 50, data = dailyBoth)
grangertest(daily ~ dailyBr, order = 100, data = dailyBoth)
grangertest(dailyBr ~ daily, order = 1, data = dailyBoth)
grangertest(dailyBr ~ daily, order = 2, data = dailyBoth)
grangertest(dailyBr ~ daily, order = 3, data = dailyBoth)
grangertest(dailyBr ~ daily, order = 5, data = dailyBoth)
grangertest(dailyBr ~ daily, order = 10, data = dailyBoth)
grangertest(dailyBr ~ daily, order = 20, data = dailyBoth)
grangertest(dailyBr ~ daily, order = 50, data = dailyBoth)
grangertest(dailyBr ~ daily, order = 100, data = dailyBoth)

#monthlyBr <- ts(brpr[,c(2)], start=c(1997, 1), end=c(2020, 8), frequency=12)

oil
tsplot(oil)
tsplot(log(oil))
tsplot(diff(oil))
tsplot(diff(log(oil)))
tsplot(diff(sqrt(oil)))

#u <- length(oil) - 132
#gdp2 <- ts(gdp[u:length(gdp)], start = c(1947 + floor(u/4), u %% 4), frequency=4)
oilcut <- ts(oil[1:449], start = 2000, frequency=52)
tsplot(oilcut)
tsplot(diff(oilcut))
tsplot(diff(diff(oilcut)))
```